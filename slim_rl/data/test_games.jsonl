{"prompt": "You are playing a paper-reviewer matching game. Your goal is to assign 8 reviewers to 8 papers to maximize the total affinity score.\n\nGAME RULES:\n- You can see SOME of the affinity scores between reviewers and papers\n- Your partner can see OTHER scores that you cannot see (shown as empty cells in your table)\n- Scores you don't know are marked with \"-\" in your table\n- You must collaborate with your partner to find the best assignment\n\nTO WIN, you should:\n1. ASK your partner about specific scores you don't know (e.g., \"What is the score for Ava Li reviewing BLEU?\")\n2. SHARE information when your partner asks about scores you can see\n3. PROPOSE assignments when you think you have enough information\n4. ACCEPT or REJECT your partner's proposals based on your knowledge\n\nFORMAT FOR PROPOSALS:\n[propose]\n- Ava Li: BLEU\n- Daniel Nguyen: Electra\n- Sofia Patel: GloVe\n(... assign all 8 reviewers to 8 papers)\n[/propose]\n\nYOUR VISIBLE AFFINITY SCORES:\n           - | BLEU: a Method for Automatic Evaluation of MT | Electra: Pre-training Text Encoders as Discriminators | GloVe: Global Vectors for Word Representation | GLUE: A Multi-Task Benchmark and Analysis Platform for NLU | LLaMA: Open and Efficient Foundation Language Models | RoBERTa: A Robustly Optimized BERT Pretraining Approach | QuAC: Question Answering in Context | SWAG: An Adversarial Dataset for Commonsense Inference\n      Ava Li |          142 |            - |            - |          150 |            - |           83 |            - |          253\nDaniel Nguyen |            0 |            - |            - |          119 |            - |          226 |            - |            -\n Sofia Patel |            - |          253 |           23 |            - |          257 |            - |           39 |          325\nAndrei Petrov |          265 |           67 |           95 |          361 |            - |            - |            - |            -\n Morgan Reed |          142 |           27 |            - |            - |          146 |          269 |          321 |            -\nJoseph Santos |            - |            - |          115 |            - |          380 |          150 |            - |            -\n Ethan Smith |            - |            - |            - |            - |          170 |            3 |           19 |            -\n Noah Wilson |            - |            - |           11 |            - |            - |            - |          202 |            -\n\nRemember: Your partner has information you don't have. Ask questions to gather the information you need!", "game_state": {"table": [[36, 50, 63, 38, 50, 21, 14, 64], [0, 99, 50, 30, 50, 57, 51, 73], [50, 64, 6, 50, 65, 50, 10, 82], [67, 17, 24, 91, 59, 45, 50, 18], [36, 7, 50, 50, 37, 68, 81, 50], [50, 82, 29, 50, 96, 38, 50, 50], [50, 50, 19, 50, 43, 1, 5, 50], [50, 7, 3, 50, 50, 96, 51, 50]], "mask1": [[1, 0, 0, 1, 0, 1, 0, 1], [1, 0, 0, 1, 0, 1, 0, 0], [0, 1, 1, 0, 1, 0, 1, 1], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 0, 0, 1, 1, 1, 0], [0, 0, 1, 0, 1, 1, 0, 0], [0, 0, 0, 0, 1, 1, 1, 0], [0, 0, 1, 0, 0, 0, 1, 0]], "mask2": [[0, 0, 1, 0, 0, 1, 1, 1], [0, 1, 0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 1, 1, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 1, 0, 0]], "scale1": 3.9681040837026273, "scale2": 8.193226778575102, "best_assignment_reward": 658, "action_log": []}, "ground_truth": {"table": [[36, 50, 63, 38, 50, 21, 14, 64], [0, 99, 50, 30, 50, 57, 51, 73], [50, 64, 6, 50, 65, 50, 10, 82], [67, 17, 24, 91, 59, 45, 50, 18], [36, 7, 50, 50, 37, 68, 81, 50], [50, 82, 29, 50, 96, 38, 50, 50], [50, 50, 19, 50, 43, 1, 5, 50], [50, 7, 3, 50, 50, 96, 51, 50]], "mask1": [[1, 0, 0, 1, 0, 1, 0, 1], [1, 0, 0, 1, 0, 1, 0, 0], [0, 1, 1, 0, 1, 0, 1, 1], [1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 0, 0, 1, 1, 1, 0], [0, 0, 1, 0, 1, 1, 0, 0], [0, 0, 0, 0, 1, 1, 1, 0], [0, 0, 1, 0, 0, 0, 1, 0]], "mask2": [[0, 0, 1, 0, 0, 1, 1, 1], [0, 1, 0, 0, 0, 0, 1, 1], [0, 1, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 1, 1, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 1, 0, 0]], "scale1": 3.9681040837026273, "scale2": 8.193226778575102, "best_assignment_reward": 658, "action_log": []}, "optimal_score": 658.0, "game_id": 123}
{"prompt": "You are playing a paper-reviewer matching game. Your goal is to assign 8 reviewers to 8 papers to maximize the total affinity score.\n\nGAME RULES:\n- You can see SOME of the affinity scores between reviewers and papers\n- Your partner can see OTHER scores that you cannot see (shown as empty cells in your table)\n- Scores you don't know are marked with \"-\" in your table\n- You must collaborate with your partner to find the best assignment\n\nTO WIN, you should:\n1. ASK your partner about specific scores you don't know (e.g., \"What is the score for Ava Li reviewing BLEU?\")\n2. SHARE information when your partner asks about scores you can see\n3. PROPOSE assignments when you think you have enough information\n4. ACCEPT or REJECT your partner's proposals based on your knowledge\n\nFORMAT FOR PROPOSALS:\n[propose]\n- Ava Li: BLEU\n- Daniel Nguyen: Electra\n- Sofia Patel: GloVe\n(... assign all 8 reviewers to 8 papers)\n[/propose]\n\nYOUR VISIBLE AFFINITY SCORES:\n           - | BLEU: a Method for Automatic Evaluation of MT | Electra: Pre-training Text Encoders as Discriminators | GloVe: Global Vectors for Word Representation | GLUE: A Multi-Task Benchmark and Analysis Platform for NLU | LLaMA: Open and Efficient Foundation Language Models | RoBERTa: A Robustly Optimized BERT Pretraining Approach | QuAC: Question Answering in Context | SWAG: An Adversarial Dataset for Commonsense Inference\n      Ava Li |            - |            - |          506 |            - |            - |            - |            - |          524\nDaniel Nguyen |            - |            - |          620 |          506 |            - |          288 |            - |            -\n Sofia Patel |           52 |            - |            - |          436 |            0 |            - |            - |            -\nAndrei Petrov |            - |            - |          428 |            - |            - |            - |            - |            -\n Morgan Reed |          419 |          148 |          471 |            - |           87 |            - |          297 |            -\nJoseph Santos |          742 |            - |          524 |            - |          104 |          480 |            - |            -\n Ethan Smith |            - |           43 |          314 |            - |          366 |            - |            - |            -\n Noah Wilson |           61 |          602 |            - |            - |            - |            - |           78 |            -\n\nRemember: Your partner has information you don't have. Ask questions to gather the information you need!", "game_state": {"table": [[30, 11, 58, 50, 27, 50, 50, 60], [50, 50, 71, 58, 50, 33, 50, 12], [6, 45, 63, 50, 0, 50, 50, 50], [50, 50, 49, 14, 1, 97, 50, 50], [48, 17, 54, 50, 10, 50, 34, 50], [85, 50, 60, 67, 12, 55, 50, 50], [50, 5, 36, 50, 42, 17, 41, 50], [7, 69, 50, 50, 50, 50, 9, 50]], "mask1": [[0, 0, 1, 0, 0, 0, 0, 1], [0, 0, 1, 1, 0, 1, 0, 0], [1, 0, 0, 1, 1, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0], [1, 0, 1, 0, 1, 1, 0, 0], [0, 1, 1, 0, 1, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0]], "mask2": [[1, 1, 0, 0, 1, 0, 0, 1], [0, 0, 1, 0, 0, 0, 0, 1], [0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 0, 0], [1, 1, 0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0]], "scale1": 8.737503034667368, "scale2": 5.121674108012622, "best_assignment_reward": 524, "action_log": []}, "ground_truth": {"table": [[30, 11, 58, 50, 27, 50, 50, 60], [50, 50, 71, 58, 50, 33, 50, 12], [6, 45, 63, 50, 0, 50, 50, 50], [50, 50, 49, 14, 1, 97, 50, 50], [48, 17, 54, 50, 10, 50, 34, 50], [85, 50, 60, 67, 12, 55, 50, 50], [50, 5, 36, 50, 42, 17, 41, 50], [7, 69, 50, 50, 50, 50, 9, 50]], "mask1": [[0, 0, 1, 0, 0, 0, 0, 1], [0, 0, 1, 1, 0, 1, 0, 0], [1, 0, 0, 1, 1, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0], [1, 0, 1, 0, 1, 1, 0, 0], [0, 1, 1, 0, 1, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0]], "mask2": [[1, 1, 0, 0, 1, 0, 0, 1], [0, 0, 1, 0, 0, 0, 0, 1], [0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 0, 0], [1, 1, 0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0]], "scale1": 8.737503034667368, "scale2": 5.121674108012622, "best_assignment_reward": 524, "action_log": []}, "optimal_score": 524.0, "game_id": 124}
{"prompt": "You are playing a paper-reviewer matching game. Your goal is to assign 8 reviewers to 8 papers to maximize the total affinity score.\n\nGAME RULES:\n- You can see SOME of the affinity scores between reviewers and papers\n- Your partner can see OTHER scores that you cannot see (shown as empty cells in your table)\n- Scores you don't know are marked with \"-\" in your table\n- You must collaborate with your partner to find the best assignment\n\nTO WIN, you should:\n1. ASK your partner about specific scores you don't know (e.g., \"What is the score for Ava Li reviewing BLEU?\")\n2. SHARE information when your partner asks about scores you can see\n3. PROPOSE assignments when you think you have enough information\n4. ACCEPT or REJECT your partner's proposals based on your knowledge\n\nFORMAT FOR PROPOSALS:\n[propose]\n- Ava Li: BLEU\n- Daniel Nguyen: Electra\n- Sofia Patel: GloVe\n(... assign all 8 reviewers to 8 papers)\n[/propose]\n\nYOUR VISIBLE AFFINITY SCORES:\n           - | BLEU: a Method for Automatic Evaluation of MT | Electra: Pre-training Text Encoders as Discriminators | GloVe: Global Vectors for Word Representation | GLUE: A Multi-Task Benchmark and Analysis Platform for NLU | LLaMA: Open and Efficient Foundation Language Models | RoBERTa: A Robustly Optimized BERT Pretraining Approach | QuAC: Question Answering in Context | SWAG: An Adversarial Dataset for Commonsense Inference\n      Ava Li |            - |            3 |            - |            - |           95 |            - |            - |            -\nDaniel Nguyen |            - |           29 |            - |          109 |           65 |            - |            - |            -\n Sofia Patel |          142 |            - |            - |            - |            - |            - |          281 |            -\nAndrei Petrov |            - |            - |          343 |          102 |          168 |          117 |            - |            -\n Morgan Reed |          124 |            - |            - |           25 |          347 |          266 |          223 |            -\nJoseph Santos |          325 |          329 |           98 |           65 |            - |           43 |          117 |          190\n Ethan Smith |            - |          248 |            - |            - |            - |            - |            - |          204\n Noah Wilson |            - |          201 |            - |            - |            - |           73 |          234 |            -\n\nRemember: Your partner has information you don't have. Ask questions to gather the information you need!", "game_state": {"table": [[50, 1, 10, 0, 26, 50, 50, 83], [13, 8, 58, 30, 18, 1, 77, 50], [39, 50, 50, 50, 50, 50, 77, 50], [50, 50, 94, 28, 46, 32, 50, 50], [34, 50, 50, 7, 95, 73, 61, 33], [89, 90, 27, 18, 36, 12, 32, 52], [50, 68, 50, 50, 71, 50, 15, 56], [50, 55, 2, 50, 60, 20, 64, 50]], "mask1": [[0, 1, 0, 0, 1, 0, 0, 0], [0, 1, 0, 1, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 1, 0], [0, 0, 1, 1, 1, 1, 0, 0], [1, 0, 0, 1, 1, 1, 1, 0], [1, 1, 1, 1, 0, 1, 1, 1], [0, 1, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 1, 1, 0]], "mask2": [[0, 1, 1, 1, 1, 0, 0, 1], [1, 1, 1, 0, 1, 1, 1, 0], [1, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 1, 0, 1, 0, 0, 1], [0, 1, 0, 0, 1, 0, 1, 1], [0, 1, 1, 0, 1, 0, 1, 0]], "scale1": 3.656827597150479, "scale2": 3.9397087776907393, "best_assignment_reward": 606, "action_log": []}, "ground_truth": {"table": [[50, 1, 10, 0, 26, 50, 50, 83], [13, 8, 58, 30, 18, 1, 77, 50], [39, 50, 50, 50, 50, 50, 77, 50], [50, 50, 94, 28, 46, 32, 50, 50], [34, 50, 50, 7, 95, 73, 61, 33], [89, 90, 27, 18, 36, 12, 32, 52], [50, 68, 50, 50, 71, 50, 15, 56], [50, 55, 2, 50, 60, 20, 64, 50]], "mask1": [[0, 1, 0, 0, 1, 0, 0, 0], [0, 1, 0, 1, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 1, 0], [0, 0, 1, 1, 1, 1, 0, 0], [1, 0, 0, 1, 1, 1, 1, 0], [1, 1, 1, 1, 0, 1, 1, 1], [0, 1, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 1, 1, 0]], "mask2": [[0, 1, 1, 1, 1, 0, 0, 1], [1, 1, 1, 0, 1, 1, 1, 0], [1, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 1, 0, 0, 1], [0, 0, 1, 0, 1, 0, 0, 1], [0, 1, 0, 0, 1, 0, 1, 1], [0, 1, 1, 0, 1, 0, 1, 0]], "scale1": 3.656827597150479, "scale2": 3.9397087776907393, "best_assignment_reward": 606, "action_log": []}, "optimal_score": 606.0, "game_id": 125}
{"prompt": "You are playing a paper-reviewer matching game. Your goal is to assign 8 reviewers to 8 papers to maximize the total affinity score.\n\nGAME RULES:\n- You can see SOME of the affinity scores between reviewers and papers\n- Your partner can see OTHER scores that you cannot see (shown as empty cells in your table)\n- Scores you don't know are marked with \"-\" in your table\n- You must collaborate with your partner to find the best assignment\n\nTO WIN, you should:\n1. ASK your partner about specific scores you don't know (e.g., \"What is the score for Ava Li reviewing BLEU?\")\n2. SHARE information when your partner asks about scores you can see\n3. PROPOSE assignments when you think you have enough information\n4. ACCEPT or REJECT your partner's proposals based on your knowledge\n\nFORMAT FOR PROPOSALS:\n[propose]\n- Ava Li: BLEU\n- Daniel Nguyen: Electra\n- Sofia Patel: GloVe\n(... assign all 8 reviewers to 8 papers)\n[/propose]\n\nYOUR VISIBLE AFFINITY SCORES:\n           - | BLEU: a Method for Automatic Evaluation of MT | Electra: Pre-training Text Encoders as Discriminators | GloVe: Global Vectors for Word Representation | GLUE: A Multi-Task Benchmark and Analysis Platform for NLU | LLaMA: Open and Efficient Foundation Language Models | RoBERTa: A Robustly Optimized BERT Pretraining Approach | QuAC: Question Answering in Context | SWAG: An Adversarial Dataset for Commonsense Inference\n      Ava Li |            - |            - |            - |           25 |            - |            - |            - |            -\nDaniel Nguyen |            - |          825 |            - |            - |            - |            - |          300 |          191\n Sofia Patel |          325 |            - |          700 |           83 |            - |            - |            - |          291\nAndrei Petrov |          516 |            - |            - |            - |            - |            - |            - |            -\n Morgan Reed |          550 |          258 |            - |            - |            - |          516 |            - |          291\nJoseph Santos |            - |            - |          108 |            - |            - |          266 |          450 |            -\n Ethan Smith |          708 |            - |            - |          258 |            - |            - |          266 |           50\n Noah Wilson |            - |            - |            - |            8 |            - |          708 |            - |            -\n\nRemember: Your partner has information you don't have. Ask questions to gather the information you need!", "game_state": {"table": [[6, 31, 68, 3, 6, 50, 41, 50], [50, 99, 19, 50, 13, 50, 36, 23], [39, 50, 84, 10, 50, 50, 50, 35], [62, 50, 50, 50, 57, 14, 95, 14], [66, 31, 50, 50, 27, 62, 72, 35], [50, 35, 13, 50, 50, 32, 54, 5], [85, 50, 50, 31, 50, 10, 32, 6], [50, 18, 50, 1, 5, 85, 50, 50]], "mask1": [[0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 1, 0, 1], [0, 0, 1, 0, 0, 1, 1, 0], [1, 0, 0, 1, 0, 0, 1, 1], [0, 0, 0, 1, 0, 1, 0, 0]], "mask2": [[1, 1, 1, 1, 1, 0, 1, 0], [0, 0, 1, 0, 1, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 1, 1, 1, 1], [1, 1, 0, 0, 1, 0, 1, 0], [0, 1, 1, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 1, 1, 1], [0, 1, 0, 0, 1, 0, 0, 0]], "scale1": 8.337278641320568, "scale2": 6.552452357284988, "best_assignment_reward": 598, "action_log": []}, "ground_truth": {"table": [[6, 31, 68, 3, 6, 50, 41, 50], [50, 99, 19, 50, 13, 50, 36, 23], [39, 50, 84, 10, 50, 50, 50, 35], [62, 50, 50, 50, 57, 14, 95, 14], [66, 31, 50, 50, 27, 62, 72, 35], [50, 35, 13, 50, 50, 32, 54, 5], [85, 50, 50, 31, 50, 10, 32, 6], [50, 18, 50, 1, 5, 85, 50, 50]], "mask1": [[0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 1, 0, 1], [0, 0, 1, 0, 0, 1, 1, 0], [1, 0, 0, 1, 0, 0, 1, 1], [0, 0, 0, 1, 0, 1, 0, 0]], "mask2": [[1, 1, 1, 1, 1, 0, 1, 0], [0, 0, 1, 0, 1, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 1, 1, 1, 1], [1, 1, 0, 0, 1, 0, 1, 0], [0, 1, 1, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 1, 1, 1], [0, 1, 0, 0, 1, 0, 0, 0]], "scale1": 8.337278641320568, "scale2": 6.552452357284988, "best_assignment_reward": 598, "action_log": []}, "optimal_score": 598.0, "game_id": 126}
{"prompt": "You are playing a paper-reviewer matching game. Your goal is to assign 8 reviewers to 8 papers to maximize the total affinity score.\n\nGAME RULES:\n- You can see SOME of the affinity scores between reviewers and papers\n- Your partner can see OTHER scores that you cannot see (shown as empty cells in your table)\n- Scores you don't know are marked with \"-\" in your table\n- You must collaborate with your partner to find the best assignment\n\nTO WIN, you should:\n1. ASK your partner about specific scores you don't know (e.g., \"What is the score for Ava Li reviewing BLEU?\")\n2. SHARE information when your partner asks about scores you can see\n3. PROPOSE assignments when you think you have enough information\n4. ACCEPT or REJECT your partner's proposals based on your knowledge\n\nFORMAT FOR PROPOSALS:\n[propose]\n- Ava Li: BLEU\n- Daniel Nguyen: Electra\n- Sofia Patel: GloVe\n(... assign all 8 reviewers to 8 papers)\n[/propose]\n\nYOUR VISIBLE AFFINITY SCORES:\n           - | BLEU: a Method for Automatic Evaluation of MT | Electra: Pre-training Text Encoders as Discriminators | GloVe: Global Vectors for Word Representation | GLUE: A Multi-Task Benchmark and Analysis Platform for NLU | LLaMA: Open and Efficient Foundation Language Models | RoBERTa: A Robustly Optimized BERT Pretraining Approach | QuAC: Question Answering in Context | SWAG: An Adversarial Dataset for Commonsense Inference\n      Ava Li |            - |            - |            - |            - |            - |            - |            - |            -\nDaniel Nguyen |          463 |            - |          384 |          296 |            - |          128 |            - |            -\n Sofia Patel |           39 |            - |            - |          374 |            - |            - |          291 |            -\nAndrei Petrov |            - |            - |            - |          424 |          172 |           29 |            - |           44\n Morgan Reed |          152 |            - |          212 |           44 |           64 |          113 |            - |            -\nJoseph Santos |          305 |          241 |          128 |            - |            - |          325 |          458 |          192\n Ethan Smith |           44 |            - |          226 |          370 |            0 |          473 |            - |            -\n Noah Wilson |            - |          202 |          143 |          488 |           44 |          424 |            - |            -\n\nRemember: Your partner has information you don't have. Ask questions to gather the information you need!", "game_state": {"table": [[92, 50, 50, 92, 50, 50, 50, 4], [94, 50, 78, 60, 50, 26, 51, 56], [8, 97, 50, 76, 0, 81, 59, 50], [50, 50, 11, 86, 35, 6, 50, 9], [31, 50, 43, 9, 13, 23, 8, 50], [62, 49, 26, 39, 73, 66, 93, 39], [9, 50, 46, 75, 0, 96, 50, 50], [65, 41, 29, 99, 9, 86, 70, 50]], "mask1": [[0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 1, 1, 0, 1, 0, 0], [1, 0, 0, 1, 0, 0, 1, 0], [0, 0, 0, 1, 1, 1, 0, 1], [1, 0, 1, 1, 1, 1, 0, 0], [1, 1, 1, 0, 0, 1, 1, 1], [1, 0, 1, 1, 1, 1, 0, 0], [0, 1, 1, 1, 1, 1, 0, 0]], "mask2": [[1, 0, 0, 1, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 1], [0, 1, 0, 1, 1, 1, 0, 0], [0, 0, 1, 0, 1, 1, 0, 0], [1, 0, 0, 1, 1, 0, 1, 0], [1, 0, 1, 1, 1, 1, 1, 0], [0, 0, 1, 1, 0, 0, 0, 0], [1, 0, 0, 1, 0, 0, 1, 0]], "scale1": 4.933466199212398, "scale2": 2.0008540506865105, "best_assignment_reward": 642, "action_log": []}, "ground_truth": {"table": [[92, 50, 50, 92, 50, 50, 50, 4], [94, 50, 78, 60, 50, 26, 51, 56], [8, 97, 50, 76, 0, 81, 59, 50], [50, 50, 11, 86, 35, 6, 50, 9], [31, 50, 43, 9, 13, 23, 8, 50], [62, 49, 26, 39, 73, 66, 93, 39], [9, 50, 46, 75, 0, 96, 50, 50], [65, 41, 29, 99, 9, 86, 70, 50]], "mask1": [[0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 1, 1, 0, 1, 0, 0], [1, 0, 0, 1, 0, 0, 1, 0], [0, 0, 0, 1, 1, 1, 0, 1], [1, 0, 1, 1, 1, 1, 0, 0], [1, 1, 1, 0, 0, 1, 1, 1], [1, 0, 1, 1, 1, 1, 0, 0], [0, 1, 1, 1, 1, 1, 0, 0]], "mask2": [[1, 0, 0, 1, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 1], [0, 1, 0, 1, 1, 1, 0, 0], [0, 0, 1, 0, 1, 1, 0, 0], [1, 0, 0, 1, 1, 0, 1, 0], [1, 0, 1, 1, 1, 1, 1, 0], [0, 0, 1, 1, 0, 0, 0, 0], [1, 0, 0, 1, 0, 0, 1, 0]], "scale1": 4.933466199212398, "scale2": 2.0008540506865105, "best_assignment_reward": 642, "action_log": []}, "optimal_score": 642.0, "game_id": 127}
