+ cd /home/nickatomlin/georgiazhou/new_dialop/RL-matching
+ export PYTHONPATH=/home/nickatomlin/georgiazhou/new_dialop/verl:/home/nickatomlin/georgiazhou/new_dialop/RL-matching
+ PYTHONPATH=/home/nickatomlin/georgiazhou/new_dialop/verl:/home/nickatomlin/georgiazhou/new_dialop/RL-matching
+ export CUDA_VISIBLE_DEVICES=4,5
+ CUDA_VISIBLE_DEVICES=4,5
+ export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
+ conda run -n verl311 python -m verl.trainer.main_ppo algorithm.adv_estimator=grpo algorithm.use_kl_in_reward=false 'data.train_files=["/home/nickatomlin/georgiazhou/new_dialop/RL-matching/data/matching.parquet"]' 'data.val_files=["/home/nickatomlin/georgiazhou/new_dialop/RL-matching/data/matching.parquet"]' data.prompt_key=messages data.train_batch_size=32 data.max_prompt_length=1024 data.max_response_length=256 data.filter_overlong_prompts=true data.truncation=left data.return_raw_chat=true actor_rollout_ref.model.path=Qwen/Qwen2.5-7B-Instruct actor_rollout_ref.model.enable_gradient_checkpointing=true actor_rollout_ref.model.use_remove_padding=true actor_rollout_ref.model.lora_rank=8 actor_rollout_ref.model.lora_alpha=16 'actor_rollout_ref.model.target_modules=["q_proj","k_proj","v_proj","o_proj"]' actor_rollout_ref.actor.ppo_mini_batch_size=32 actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 actor_rollout_ref.actor.use_torch_compile=false actor_rollout_ref.actor.fsdp_config.param_offload=true actor_rollout_ref.actor.fsdp_config.optimizer_offload=true actor_rollout_ref.rollout.name=sglang actor_rollout_ref.rollout.multi_turn.enable=true actor_rollout_ref.rollout.multi_turn.interaction_config_path=/home/nickatomlin/georgiazhou/new_dialop/RL-matching/configs/matching_interaction.yaml actor_rollout_ref.rollout.prompt_length=1024 actor_rollout_ref.rollout.response_length=256 actor_rollout_ref.rollout.n=2 actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.gpu_memory_utilization=0.5 actor_rollout_ref.rollout.enable_chunked_prefill=true actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=1 actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=1 critic.model.path=Qwen/Qwen2.5-7B-Instruct critic.model.enable_gradient_checkpointing=true critic.model.use_remove_padding=true critic.model.lora_rank=8 critic.model.lora_alpha=16 'critic.model.target_modules=["q_proj","k_proj","v_proj","o_proj"]' critic.ppo_micro_batch_size_per_gpu=1 reward_model.enable=false trainer.project_name=verl_matching trainer.experiment_name=grpo_7b_training_mem_opt 'trainer.logger=["console"]' trainer.n_gpus_per_node=2 trainer.nnodes=1 trainer.save_freq=1 trainer.test_freq=1 trainer.total_epochs=3 trainer.critic_warmup=0
[36m(TaskRunner pid=2301042)[0m TaskRunner hostname: nlp1, PID: 2301042
[36m(TaskRunner pid=2301042)[0m {'actor_rollout_ref': {'actor': {'_target_': 'verl.workers.config.FSDPActorConfig',
[36m(TaskRunner pid=2301042)[0m                                  'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig',
[36m(TaskRunner pid=2301042)[0m                                                 'async_save': False,
[36m(TaskRunner pid=2301042)[0m                                                 'load_contents': ['model',
[36m(TaskRunner pid=2301042)[0m                                                                   'optimizer',
[36m(TaskRunner pid=2301042)[0m                                                                   'extra'],
[36m(TaskRunner pid=2301042)[0m                                                 'save_contents': ['model',
[36m(TaskRunner pid=2301042)[0m                                                                   'optimizer',
[36m(TaskRunner pid=2301042)[0m                                                                   'extra']},
[36m(TaskRunner pid=2301042)[0m                                  'clip_ratio': 0.2,
[36m(TaskRunner pid=2301042)[0m                                  'clip_ratio_c': 3.0,
[36m(TaskRunner pid=2301042)[0m                                  'clip_ratio_high': 0.2,
[36m(TaskRunner pid=2301042)[0m                                  'clip_ratio_low': 0.2,
[36m(TaskRunner pid=2301042)[0m                                  'entropy_checkpointing': False,
[36m(TaskRunner pid=2301042)[0m                                  'entropy_coeff': 0,
[36m(TaskRunner pid=2301042)[0m                                  'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=2301042)[0m                                  'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',
[36m(TaskRunner pid=2301042)[0m                                                  'forward_prefetch': False,
[36m(TaskRunner pid=2301042)[0m                                                  'fsdp_size': -1,
[36m(TaskRunner pid=2301042)[0m                                                  'offload_policy': False,
[36m(TaskRunner pid=2301042)[0m                                                  'optimizer_offload': True,
[36m(TaskRunner pid=2301042)[0m                                                  'param_offload': True,
[36m(TaskRunner pid=2301042)[0m                                                  'reshard_after_forward': True,
[36m(TaskRunner pid=2301042)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=2301042)[0m                                  'grad_clip': 1.0,
[36m(TaskRunner pid=2301042)[0m                                  'kl_loss_coef': 0.001,
[36m(TaskRunner pid=2301042)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(TaskRunner pid=2301042)[0m                                  'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=2301042)[0m                                  'optim': {'_target_': 'verl.workers.config.FSDPOptimizerConfig',
[36m(TaskRunner pid=2301042)[0m                                            'lr': 1e-06,
[36m(TaskRunner pid=2301042)[0m                                            'lr_warmup_steps': -1,
[36m(TaskRunner pid=2301042)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=2301042)[0m                                            'min_lr_ratio': 0.0,
[36m(TaskRunner pid=2301042)[0m                                            'num_cycles': 0.5,
[36m(TaskRunner pid=2301042)[0m                                            'total_training_steps': -1,
[36m(TaskRunner pid=2301042)[0m                                            'warmup_style': 'constant',
[36m(TaskRunner pid=2301042)[0m                                            'weight_decay': 0.01},
[36m(TaskRunner pid=2301042)[0m                                  'policy_loss': {'_target_': 'verl.workers.config.PolicyLossConfig',
[36m(TaskRunner pid=2301042)[0m                                                  'clip_cov_lb': 1.0,
[36m(TaskRunner pid=2301042)[0m                                                  'clip_cov_ratio': 0.0002,
[36m(TaskRunner pid=2301042)[0m                                                  'clip_cov_ub': 5.0,
[36m(TaskRunner pid=2301042)[0m                                                  'kl_cov_ratio': 0.0002,
[36m(TaskRunner pid=2301042)[0m                                                  'loss_mode': 'vanilla',
[36m(TaskRunner pid=2301042)[0m                                                  'ppo_kl_coef': 0.1},
[36m(TaskRunner pid=2301042)[0m                                  'ppo_epochs': 1,
[36m(TaskRunner pid=2301042)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=2301042)[0m                                  'ppo_micro_batch_size': None,
[36m(TaskRunner pid=2301042)[0m                                  'ppo_micro_batch_size_per_gpu': 1,
[36m(TaskRunner pid=2301042)[0m                                  'ppo_mini_batch_size': 32,
[36m(TaskRunner pid=2301042)[0m                                  'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=2301042)[0m                                               'all_ranks': False,
[36m(TaskRunner pid=2301042)[0m                                               'enable': False,
[36m(TaskRunner pid=2301042)[0m                                               'ranks': [],
[36m(TaskRunner pid=2301042)[0m                                               'save_path': 'outputs/profile',
[36m(TaskRunner pid=2301042)[0m                                               'tool': None,
[36m(TaskRunner pid=2301042)[0m                                               'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                                       'analysis': True,
[36m(TaskRunner pid=2301042)[0m                                                                       'contents': [],
[36m(TaskRunner pid=2301042)[0m                                                                       'level': 'level1'},
[36m(TaskRunner pid=2301042)[0m                                                               'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                                        'discrete': False},
[36m(TaskRunner pid=2301042)[0m                                                               'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                                         'step_end': None,
[36m(TaskRunner pid=2301042)[0m                                                                         'step_start': 0}}},
[36m(TaskRunner pid=2301042)[0m                                  'shuffle': False,
[36m(TaskRunner pid=2301042)[0m                                  'strategy': 'fsdp',
[36m(TaskRunner pid=2301042)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=2301042)[0m                                  'use_dynamic_bsz': False,
[36m(TaskRunner pid=2301042)[0m                                  'use_fused_kernels': False,
[36m(TaskRunner pid=2301042)[0m                                  'use_kl_loss': False,
[36m(TaskRunner pid=2301042)[0m                                  'use_remove_padding': True,
[36m(TaskRunner pid=2301042)[0m                                  'use_torch_compile': False},
[36m(TaskRunner pid=2301042)[0m                        'hybrid_engine': True,
[36m(TaskRunner pid=2301042)[0m                        'model': {'custom_chat_template': None,
[36m(TaskRunner pid=2301042)[0m                                  'enable_activation_offload': False,
[36m(TaskRunner pid=2301042)[0m                                  'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=2301042)[0m                                  'exclude_modules': None,
[36m(TaskRunner pid=2301042)[0m                                  'external_lib': None,
[36m(TaskRunner pid=2301042)[0m                                  'fused_kernel_options': {'impl_backend': 'torch'},
[36m(TaskRunner pid=2301042)[0m                                  'lora_alpha': 16,
[36m(TaskRunner pid=2301042)[0m                                  'lora_rank': 8,
[36m(TaskRunner pid=2301042)[0m                                  'override_config': {},
[36m(TaskRunner pid=2301042)[0m                                  'path': 'Qwen/Qwen2.5-7B-Instruct',
[36m(TaskRunner pid=2301042)[0m                                  'target_modules': ['q_proj',
[36m(TaskRunner pid=2301042)[0m                                                     'k_proj',
[36m(TaskRunner pid=2301042)[0m                                                     'v_proj',
[36m(TaskRunner pid=2301042)[0m                                                     'o_proj'],
[36m(TaskRunner pid=2301042)[0m                                  'trust_remote_code': False,
[36m(TaskRunner pid=2301042)[0m                                  'use_fused_kernels': False,
[36m(TaskRunner pid=2301042)[0m                                  'use_liger': False,
[36m(TaskRunner pid=2301042)[0m                                  'use_remove_padding': True,
[36m(TaskRunner pid=2301042)[0m                                  'use_shm': False},
[36m(TaskRunner pid=2301042)[0m                        'nccl_timeout': 600,
[36m(TaskRunner pid=2301042)[0m                        'ref': {'entropy_checkpointing': False,
[36m(TaskRunner pid=2301042)[0m                                'entropy_from_logits_with_chunking': False,
[36m(TaskRunner pid=2301042)[0m                                'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',
[36m(TaskRunner pid=2301042)[0m                                                'forward_prefetch': False,
[36m(TaskRunner pid=2301042)[0m                                                'param_offload': False,
[36m(TaskRunner pid=2301042)[0m                                                'reshard_after_forward': True,
[36m(TaskRunner pid=2301042)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=2301042)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=2301042)[0m                                'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=2301042)[0m                                'log_prob_micro_batch_size_per_gpu': 1,
[36m(TaskRunner pid=2301042)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=2301042)[0m                                'model': None,
[36m(TaskRunner pid=2301042)[0m                                'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=2301042)[0m                                             'all_ranks': False,
[36m(TaskRunner pid=2301042)[0m                                             'enable': False,
[36m(TaskRunner pid=2301042)[0m                                             'ranks': [],
[36m(TaskRunner pid=2301042)[0m                                             'save_path': 'outputs/profile',
[36m(TaskRunner pid=2301042)[0m                                             'tool': None,
[36m(TaskRunner pid=2301042)[0m                                             'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                                     'analysis': True,
[36m(TaskRunner pid=2301042)[0m                                                                     'contents': [],
[36m(TaskRunner pid=2301042)[0m                                                                     'level': 'level1'},
[36m(TaskRunner pid=2301042)[0m                                                             'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                                      'discrete': False},
[36m(TaskRunner pid=2301042)[0m                                                             'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                                       'step_end': None,
[36m(TaskRunner pid=2301042)[0m                                                                       'step_start': 0}}},
[36m(TaskRunner pid=2301042)[0m                                'strategy': 'fsdp',
[36m(TaskRunner pid=2301042)[0m                                'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=2301042)[0m                                'use_torch_compile': False},
[36m(TaskRunner pid=2301042)[0m                        'rollout': {'agent': {'agent_loop_config_path': None,
[36m(TaskRunner pid=2301042)[0m                                              'custom_async_server': {'name': None,
[36m(TaskRunner pid=2301042)[0m                                                                      'path': None},
[36m(TaskRunner pid=2301042)[0m                                              'num_workers': 8},
[36m(TaskRunner pid=2301042)[0m                                    'calculate_log_probs': False,
[36m(TaskRunner pid=2301042)[0m                                    'cudagraph_capture_sizes': None,
[36m(TaskRunner pid=2301042)[0m                                    'disable_log_stats': True,
[36m(TaskRunner pid=2301042)[0m                                    'do_sample': True,
[36m(TaskRunner pid=2301042)[0m                                    'dtype': 'bfloat16',
[36m(TaskRunner pid=2301042)[0m                                    'enable_chunked_prefill': True,
[36m(TaskRunner pid=2301042)[0m                                    'enforce_eager': False,
[36m(TaskRunner pid=2301042)[0m                                    'engine_kwargs': {'sglang': {'attention_backend': None},
[36m(TaskRunner pid=2301042)[0m                                                      'vllm': {'disable_mm_preprocessor_cache': False,
[36m(TaskRunner pid=2301042)[0m                                                               'swap_space': None}},
[36m(TaskRunner pid=2301042)[0m                                    'free_cache_engine': True,
[36m(TaskRunner pid=2301042)[0m                                    'gpu_memory_utilization': 0.5,
[36m(TaskRunner pid=2301042)[0m                                    'ignore_eos': False,
[36m(TaskRunner pid=2301042)[0m                                    'layered_summon': False,
[36m(TaskRunner pid=2301042)[0m                                    'load_format': 'dummy_dtensor',
[36m(TaskRunner pid=2301042)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(TaskRunner pid=2301042)[0m                                    'log_prob_micro_batch_size': None,
[36m(TaskRunner pid=2301042)[0m                                    'log_prob_micro_batch_size_per_gpu': 1,
[36m(TaskRunner pid=2301042)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(TaskRunner pid=2301042)[0m                                    'max_model_len': None,
[36m(TaskRunner pid=2301042)[0m                                    'max_num_batched_tokens': 8192,
[36m(TaskRunner pid=2301042)[0m                                    'max_num_seqs': 1024,
[36m(TaskRunner pid=2301042)[0m                                    'mode': 'sync',
[36m(TaskRunner pid=2301042)[0m                                    'multi_stage_wake_up': False,
[36m(TaskRunner pid=2301042)[0m                                    'multi_turn': {'enable': True,
[36m(TaskRunner pid=2301042)[0m                                                   'format': 'hermes',
[36m(TaskRunner pid=2301042)[0m                                                   'interaction_config_path': '/home/nickatomlin/georgiazhou/new_dialop/RL-matching/configs/matching_interaction.yaml',
[36m(TaskRunner pid=2301042)[0m                                                   'max_assistant_turns': None,
[36m(TaskRunner pid=2301042)[0m                                                   'max_parallel_calls': 1,
[36m(TaskRunner pid=2301042)[0m                                                   'max_tool_response_length': 256,
[36m(TaskRunner pid=2301042)[0m                                                   'max_user_turns': None,
[36m(TaskRunner pid=2301042)[0m                                                   'tokenization_sanity_check_mode': 'strict',
[36m(TaskRunner pid=2301042)[0m                                                   'tool_config_path': None,
[36m(TaskRunner pid=2301042)[0m                                                   'tool_response_truncate_side': 'middle',
[36m(TaskRunner pid=2301042)[0m                                                   'use_inference_chat_template': False},
[36m(TaskRunner pid=2301042)[0m                                    'n': 2,
[36m(TaskRunner pid=2301042)[0m                                    'name': 'sglang',
[36m(TaskRunner pid=2301042)[0m                                    'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=2301042)[0m                                                 'all_ranks': False,
[36m(TaskRunner pid=2301042)[0m                                                 'enable': False,
[36m(TaskRunner pid=2301042)[0m                                                 'ranks': [],
[36m(TaskRunner pid=2301042)[0m                                                 'save_path': 'outputs/profile',
[36m(TaskRunner pid=2301042)[0m                                                 'tool': None,
[36m(TaskRunner pid=2301042)[0m                                                 'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                                         'analysis': True,
[36m(TaskRunner pid=2301042)[0m                                                                         'contents': [],
[36m(TaskRunner pid=2301042)[0m                                                                         'level': 'level1'},
[36m(TaskRunner pid=2301042)[0m                                                                 'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                                          'discrete': False},
[36m(TaskRunner pid=2301042)[0m                                                                 'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                                           'step_end': None,
[36m(TaskRunner pid=2301042)[0m                                                                           'step_start': 0}}},
[36m(TaskRunner pid=2301042)[0m                                    'prompt_length': 1024,
[36m(TaskRunner pid=2301042)[0m                                    'response_length': 256,
[36m(TaskRunner pid=2301042)[0m                                    'skip_dump_dir': '/tmp/rollout_dump',
[36m(TaskRunner pid=2301042)[0m                                    'skip_rollout': False,
[36m(TaskRunner pid=2301042)[0m                                    'temperature': 1.0,
[36m(TaskRunner pid=2301042)[0m                                    'tensor_model_parallel_size': 1,
[36m(TaskRunner pid=2301042)[0m                                    'top_k': -1,
[36m(TaskRunner pid=2301042)[0m                                    'top_p': 1,
[36m(TaskRunner pid=2301042)[0m                                    'trace': {'backend': None,
[36m(TaskRunner pid=2301042)[0m                                              'token2text': False},
[36m(TaskRunner pid=2301042)[0m                                    'update_weights_bucket_megabytes': 512,
[36m(TaskRunner pid=2301042)[0m                                    'val_kwargs': 
[36m(TaskRunner pid=2301042)[0m {'do_sample': False,
[36m(TaskRunner pid=2301042)[0m                                                   'n': 1,
[36m(TaskRunner pid=2301042)[0m                                                   'temperature': 0,
[36m(TaskRunner pid=2301042)[0m                                                   'top_k': -1,
[36m(TaskRunner pid=2301042)[0m                                                   'top_p': 1.0}}},
[36m(TaskRunner pid=2301042)[0m  'algorithm': {'_target_': 'verl.trainer.config.AlgoConfig',
[36m(TaskRunner pid=2301042)[0m                'adv_estimator': 'grpo',
[36m(TaskRunner pid=2301042)[0m                'gamma': 1.0,
[36m(TaskRunner pid=2301042)[0m                'kl_ctrl': {'_target_': 'verl.trainer.config.KLControlConfig',
[36m(TaskRunner pid=2301042)[0m                            'horizon': 10000,
[36m(TaskRunner pid=2301042)[0m                            'kl_coef': 0.001,
[36m(TaskRunner pid=2301042)[0m                            'target_kl': 0.1,
[36m(TaskRunner pid=2301042)[0m                            'type': 'fixed'},
[36m(TaskRunner pid=2301042)[0m                'kl_penalty': 'kl',
[36m(TaskRunner pid=2301042)[0m                'lam': 1.0,
[36m(TaskRunner pid=2301042)[0m                'norm_adv_by_std_in_grpo': True,
[36m(TaskRunner pid=2301042)[0m                'pf_ppo': {'reweight_method': 'pow', 'weight_pow': 2.0},
[36m(TaskRunner pid=2301042)[0m                'use_kl_in_reward': False,
[36m(TaskRunner pid=2301042)[0m                'use_pf_ppo': False},
[36m(TaskRunner pid=2301042)[0m  'critic': {'_target_': 'verl.workers.config.FSDPCriticConfig',
[36m(TaskRunner pid=2301042)[0m             'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig',
[36m(TaskRunner pid=2301042)[0m                            'async_save': False,
[36m(TaskRunner pid=2301042)[0m                            'load_contents': ['model', 'optimizer', 'extra'],
[36m(TaskRunner pid=2301042)[0m                            'save_contents': ['model', 'optimizer', 'extra']},
[36m(TaskRunner pid=2301042)[0m             'cliprange_value': 0.5,
[36m(TaskRunner pid=2301042)[0m             'enable': None,
[36m(TaskRunner pid=2301042)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=2301042)[0m             'forward_micro_batch_size': None,
[36m(TaskRunner pid=2301042)[0m             'forward_micro_batch_size_per_gpu': 1,
[36m(TaskRunner pid=2301042)[0m             'grad_clip': 1.0,
[36m(TaskRunner pid=2301042)[0m             'loss_agg_mode': 'token-mean',
[36m(TaskRunner pid=2301042)[0m             'model': {'_target_': 'verl.workers.config.FSDPCriticModelCfg',
[36m(TaskRunner pid=2301042)[0m                       'enable_activation_offload': False,
[36m(TaskRunner pid=2301042)[0m                       'enable_gradient_checkpointing': True,
[36m(TaskRunner pid=2301042)[0m                       'external_lib': None,
[36m(TaskRunner pid=2301042)[0m                       'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',
[36m(TaskRunner pid=2301042)[0m                                       'forward_prefetch': False,
[36m(TaskRunner pid=2301042)[0m                                       'fsdp_size': -1,
[36m(TaskRunner pid=2301042)[0m                                       'offload_policy': False,
[36m(TaskRunner pid=2301042)[0m                                       'optimizer_offload': False,
[36m(TaskRunner pid=2301042)[0m                                       'param_offload': False,
[36m(TaskRunner pid=2301042)[0m                                       'reshard_after_forward': True,
[36m(TaskRunner pid=2301042)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=2301042)[0m                       'lora_alpha': 16,
[36m(TaskRunner pid=2301042)[0m                       'lora_rank': 8,
[36m(TaskRunner pid=2301042)[0m                       'override_config': {},
[36m(TaskRunner pid=2301042)[0m                       'path': 'Qwen/Qwen2.5-7B-Instruct',
[36m(TaskRunner pid=2301042)[0m                       'target_modules': ['q_proj',
[36m(TaskRunner pid=2301042)[0m                                          'k_proj',
[36m(TaskRunner pid=2301042)[0m                                          'v_proj',
[36m(TaskRunner pid=2301042)[0m                                          'o_proj'],
[36m(TaskRunner pid=2301042)[0m                       'tokenizer_path': 'Qwen/Qwen2.5-7B-Instruct',
[36m(TaskRunner pid=2301042)[0m                       'trust_remote_code': False,
[36m(TaskRunner pid=2301042)[0m                       'use_remove_padding': True,
[36m(TaskRunner pid=2301042)[0m                       'use_shm': False},
[36m(TaskRunner pid=2301042)[0m             'optim': {'_target_': 'verl.workers.config.FSDPOptimizerConfig',
[36m(TaskRunner pid=2301042)[0m                       'lr': 1e-05,
[36m(TaskRunner pid=2301042)[0m                       'lr_warmup_steps': -1,
[36m(TaskRunner pid=2301042)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(TaskRunner pid=2301042)[0m                       'min_lr_ratio': None,
[36m(TaskRunner pid=2301042)[0m                       'total_training_steps': -1,
[36m(TaskRunner pid=2301042)[0m                       'warmup_style': 'constant',
[36m(TaskRunner pid=2301042)[0m                       'weight_decay': 0.01},
[36m(TaskRunner pid=2301042)[0m             'ppo_epochs': 1,
[36m(TaskRunner pid=2301042)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=2301042)[0m             'ppo_micro_batch_size': None,
[36m(TaskRunner pid=2301042)[0m             'ppo_micro_batch_size_per_gpu': 1,
[36m(TaskRunner pid=2301042)[0m             'ppo_mini_batch_size': 32,
[36m(TaskRunner pid=2301042)[0m             'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=2301042)[0m                          'all_ranks': False,
[36m(TaskRunner pid=2301042)[0m                          'enable': False,
[36m(TaskRunner pid=2301042)[0m                          'ranks': [],
[36m(TaskRunner pid=2301042)[0m                          'save_path': 'outputs/profile',
[36m(TaskRunner pid=2301042)[0m                          'tool': None,
[36m(TaskRunner pid=2301042)[0m                          'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                  'analysis': True,
[36m(TaskRunner pid=2301042)[0m                                                  'contents': [],
[36m(TaskRunner pid=2301042)[0m                                                  'level': 'level1'},
[36m(TaskRunner pid=2301042)[0m                                          'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                   'discrete': False},
[36m(TaskRunner pid=2301042)[0m                                          'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                    'step_end': None,
[36m(TaskRunner pid=2301042)[0m                                                    'step_start': 0}}},
[36m(TaskRunner pid=2301042)[0m             'rollout_n': 2,
[36m(TaskRunner pid=2301042)[0m             'shuffle': False,
[36m(TaskRunner pid=2301042)[0m             'strategy': 'fsdp',
[36m(TaskRunner pid=2301042)[0m             'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=2301042)[0m             'use_dynamic_bsz': False},
[36m(TaskRunner pid=2301042)[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},
[36m(TaskRunner pid=2301042)[0m  'data': {'apply_chat_template_kwargs': {},
[36m(TaskRunner pid=2301042)[0m           'custom_cls': {'name': None, 'path': None},
[36m(TaskRunner pid=2301042)[0m           'datagen': {'name': None, 'path': None},
[36m(TaskRunner pid=2301042)[0m           'dataloader_num_workers': 8,
[36m(TaskRunner pid=2301042)[0m           'filter_overlong_prompts': True,
[36m(TaskRunner pid=2301042)[0m           'filter_overlong_prompts_workers': 1,
[36m(TaskRunner pid=2301042)[0m           'image_key': 'images',
[36m(TaskRunner pid=2301042)[0m           'max_prompt_length': 1024,
[36m(TaskRunner pid=2301042)[0m           'max_response_length': 256,
[36m(TaskRunner pid=2301042)[0m           'prompt_key': 'messages',
[36m(TaskRunner pid=2301042)[0m           'return_full_prompt': False,
[36m(TaskRunner pid=2301042)[0m           'return_multi_modal_inputs': True,
[36m(TaskRunner pid=2301042)[0m           'return_raw_chat': True,
[36m(TaskRunner pid=2301042)[0m           'return_raw_input_ids': False,
[36m(TaskRunner pid=2301042)[0m           'reward_fn_key': 'data_source',
[36m(TaskRunner pid=2301042)[0m           'sampler': {'class_name': None, 'class_path': None},
[36m(TaskRunner pid=2301042)[0m           'shuffle': True,
[36m(TaskRunner pid=2301042)[0m           'tokenizer': None,
[36m(TaskRunner pid=2301042)[0m           'train_batch_size': 32,
[36m(TaskRunner pid=2301042)[0m           'train_files': ['/home/nickatomlin/georgiazhou/new_dialop/RL-matching/data/matching.parquet'],
[36m(TaskRunner pid=2301042)[0m           'truncation': 'left',
[36m(TaskRunner pid=2301042)[0m           'trust_remote_code': False,
[36m(TaskRunner pid=2301042)[0m           'use_shm': False,
[36m(TaskRunner pid=2301042)[0m           'val_batch_size': None,
[36m(TaskRunner pid=2301042)[0m           'val_files': ['/home/nickatomlin/georgiazhou/new_dialop/RL-matching/data/matching.parquet'],
[36m(TaskRunner pid=2301042)[0m           'validation_shuffle': False,
[36m(TaskRunner pid=2301042)[0m           'video_key': 'videos'},
[36m(TaskRunner pid=2301042)[0m  'global_profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=2301042)[0m                      'global_tool_config': {'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                      'controller_nsight_options': {'cuda-graph-trace': 'graph',
[36m(TaskRunner pid=2301042)[0m                                                                                    'cuda-memory-usage': 'true',
[36m(TaskRunner pid=2301042)[0m                                                                                    'trace': 'cuda,nvtx,cublas,ucx'},
[36m(TaskRunner pid=2301042)[0m                                                      'discrete': False,
[36m(TaskRunner pid=2301042)[0m                                                      'worker_nsight_options': {'capture-range': 'cudaProfilerApi',
[36m(TaskRunner pid=2301042)[0m                                                                                'capture-range-end': None,
[36m(TaskRunner pid=2301042)[0m                                                                                'cuda-graph-trace': 'graph',
[36m(TaskRunner pid=2301042)[0m                                                                                'cuda-memory-usage': 'true',
[36m(TaskRunner pid=2301042)[0m                                                                                'kill': 'none',
[36m(TaskRunner pid=2301042)[0m                                                                                'trace': 'cuda,nvtx,cublas,ucx'}}},
[36m(TaskRunner pid=2301042)[0m                      'profile_continuous_steps': False,
[36m(TaskRunner pid=2301042)[0m                      'save_path': 'outputs/profile',
[36m(TaskRunner pid=2301042)[0m                      'steps': None,
[36m(TaskRunner pid=2301042)[0m                      'tool': None},
[36m(TaskRunner pid=2301042)[0m  'ray_init': {'num_cpus': None, 'timeline_json_file': None},
[36m(TaskRunner pid=2301042)[0m  'reward_model': {'enable': False,
[36m(TaskRunner pid=2301042)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(TaskRunner pid=2301042)[0m                   'launch_reward_fn_async': False,
[36m(TaskRunner pid=2301042)[0m                   'max_length': None,
[36m(TaskRunner pid=2301042)[0m                   'micro_batch_size': None,
[36m(TaskRunner pid=2301042)[0m                   'micro_batch_size_per_gpu': None,
[36m(TaskRunner pid=2301042)[0m                   'model': {'external_lib': None,
[36m(TaskRunner pid=2301042)[0m                             'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',
[36m(TaskRunner pid=2301042)[0m                                             'forward_prefetch': False,
[36m(TaskRunner pid=2301042)[0m                                             'fsdp_size': -1,
[36m(TaskRunner pid=2301042)[0m                                             'param_offload': False,
[36m(TaskRunner pid=2301042)[0m                                             'reshard_after_forward': True,
[36m(TaskRunner pid=2301042)[0m                                             'wrap_policy': {'min_num_params': 0}},
[36m(TaskRunner pid=2301042)[0m                             'input_tokenizer': 'Qwen/Qwen2.5-7B-Instruct',
[36m(TaskRunner pid=2301042)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(TaskRunner pid=2301042)[0m                             'trust_remote_code': False,
[36m(TaskRunner pid=2301042)[0m                             'use_fused_kernels': False,
[36m(TaskRunner pid=2301042)[0m                             'use_remove_padding': False,
[36m(TaskRunner pid=2301042)[0m                             'use_shm': False},
[36m(TaskRunner pid=2301042)[0m                   'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',
[36m(TaskRunner pid=2301042)[0m                                'all_ranks': False,
[36m(TaskRunner pid=2301042)[0m                                'enable': False,
[36m(TaskRunner pid=2301042)[0m                                'ranks': [],
[36m(TaskRunner pid=2301042)[0m                                'save_path': 'outputs/profile',
[36m(TaskRunner pid=2301042)[0m                                'tool': None,
[36m(TaskRunner pid=2301042)[0m                                'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                        'analysis': True,
[36m(TaskRunner pid=2301042)[0m                                                        'contents': [],
[36m(TaskRunner pid=2301042)[0m                                                        'level': 'level1'},
[36m(TaskRunner pid=2301042)[0m                                                'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                         'discrete': False},
[36m(TaskRunner pid=2301042)[0m                                                'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',
[36m(TaskRunner pid=2301042)[0m                                                          'step_end': None,
[36m(TaskRunner pid=2301042)[0m                                                          'step_start': 0}}},
[36m(TaskRunner pid=2301042)[0m                   'reward_manager': 'naive',
[36m(TaskRunner pid=2301042)[0m                   'sandbox_fusion': {'max_concurrent': 64,
[36m(TaskRunner pid=2301042)[0m                                      'memory_limit_mb': 1024,
[36m(TaskRunner pid=2301042)[0m                                      'url': None},
[36m(TaskRunner pid=2301042)[0m                   'strategy': 'fsdp',
[36m(TaskRunner pid=2301042)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(TaskRunner pid=2301042)[0m                   'use_dynamic_bsz': False},
[36m(TaskRunner pid=2301042)[0m  'trainer': {'balance_batch': True,
[36m(TaskRunner pid=2301042)[0m              'critic_warmup': 0,
[36m(TaskRunner pid=2301042)[0m              'default_hdfs_dir': None,
[36m(TaskRunner pid=2301042)[0m              'default_local_dir': 'checkpoints/verl_matching/grpo_7b_training_mem_opt',
[36m(TaskRunner pid=2301042)[0m              'del_local_ckpt_after_load': False,
[36m(TaskRunner pid=2301042)[0m              'device': 'cuda',
[36m(TaskRunner pid=2301042)[0m              'esi_redundant_time': 0,
[36m(TaskRunner pid=2301042)[0m              'experiment_name': 'grpo_7b_training_mem_opt',
[36m(TaskRunner pid=2301042)[0m              'log_val_generations': 0,
[36m(TaskRunner pid=2301042)[0m              'logger': ['console'],
[36m(TaskRunner pid=2301042)[0m              'max_actor_ckpt_to_keep': None,
[36m(TaskRunner pid=2301042)[0m              'max_critic_ckpt_to_keep': None,
[36m(TaskRunner pid=2301042)[0m              'n_gpus_per_node': 2,
[36m(TaskRunner pid=2301042)[0m              'nnodes': 1,
[36m(TaskRunner pid=2301042)[0m              'project_name': 'verl_matching',
[36m(TaskRunner pid=2301042)[0m              'ray_wait_register_center_timeout': 300,
[36m(TaskRunner pid=2301042)[0m              'resume_from_path': None,
[36m(TaskRunner pid=2301042)[0m              'resume_mode': 'auto',
[36m(TaskRunner pid=2301042)[0m              'rollout_data_dir': None,
[36m(TaskRunner pid=2301042)[0m              'save_freq': 1,
[36m(TaskRunner pid=2301042)[0m              'test_freq': 1,
[36m(TaskRunner pid=2301042)[0m              'total_epochs': 3,
[36m(TaskRunner pid=2301042)[0m              'total_training_steps': None,
[36m(TaskRunner pid=2301042)[0m              'use_legacy_worker_impl': 'auto',
[36m(TaskRunner pid=2301042)[0m              'val_before_train': True,
[36m(TaskRunner pid=2301042)[0m              'val_only': False,
[36m(TaskRunner pid=2301042)[0m              'validation_data_dir': None}}
[36m(TaskRunner pid=2301042)[0m Using dataset class: RLHFDataset
[36m(TaskRunner pid=2301042)[0m dataset len: 134
[36m(TaskRunner pid=2301042)[0m filter dataset len: 120
[36m(TaskRunner pid=2301042)[0m Using dataset class: RLHFDataset
[36m(TaskRunner pid=2301042)[0m dataset len: 134
[36m(TaskRunner pid=2301042)[0m filter dataset len: 120
[36m(TaskRunner pid=2301042)[0m [validate_config] All configuration checks passed successfully!
[36m(TaskRunner pid=2301042)[0m Size of train dataloader: 3, Size of val dataloader: 1
[36m(TaskRunner pid=2301042)[0m Total training steps: 9
[36m(TaskRunner pid=2301042)[0m colocated worker base class <class 'verl.single_controller.base.worker.Worker'>
[36m(WorkerDict pid=2301407)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=2301407)[0m   "architectures": [
[36m(WorkerDict pid=2301407)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=2301407)[0m   ],
[36m(WorkerDict pid=2301407)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=2301407)[0m   "eos_token_id": 151645,
[36m(WorkerDict pid=2301407)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=2301407)[0m   "hidden_size": 3584,
[36m(WorkerDict pid=2301407)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=2301407)[0m   "intermediate_size": 18944,
[36m(WorkerDict pid=2301407)[0m   "layer_types": [
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention",
[36m(WorkerDict pid=2301407)[0m     "full_attention"
[36m(WorkerDict pid=2301407)[0m   ],
[36m(WorkerDict pid=2301407)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=2301407)[0m   "max_window_layers": 28,
[36m(WorkerDict pid=2301407)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=2301407)[0m   "num_attention_heads": 28,
[36m(WorkerDict pid=2301407)[0m   "num_hidden_layers": 28,
[36m(WorkerDict pid=2301407)[0m   "num_key_value_heads": 4,
[36m(WorkerDict pid=2301407)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=2301407)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=2301407)[0m   "rope_scaling": null,
[36m(WorkerDict pid=2301407)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=2301407)[0m   "sliding_window": null,
[36m(WorkerDict pid=2301407)[0m   "tie_word_embeddings": false,
[36m(WorkerDict pid=2301407)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=2301407)[0m   "transformers_version": "4.54.1",
[36m(WorkerDict pid=2301407)[0m   "use_cache": true,
[36m(WorkerDict pid=2301407)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=2301407)[0m   "vocab_size": 152064
[36m(WorkerDict pid=2301407)[0m }
[36m(WorkerDict pid=2301407)[0m 
[36m(WorkerDict pid=2301407)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention
[36m(WorkerDict pid=2301407)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch
[36m(WorkerDict pid=2301407)[0m Applying LoRA to actor module
[36m(WorkerDict pid=2301407)[0m PeftModelForCausalLM contains 7.62B parameters
[36m(WorkerDict pid=2301407)[0m wrap_policy: functools.partial(<function _or_policy at 0x78f69d7b4220>, policies=[functools.partial(<function lambda_auto_wrap_policy at 0x78f69d787ba0>, lambda_fn=<function get_fsdp_wrap_policy.<locals>.lambda_policy_fn at 0x78f5b89e6f20>), functools.partial(<function transformer_auto_wrap_policy at 0x78f69d7b40e0>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})])
[36m(WorkerDict pid=2301407)[0m Total steps: 9, num_warmup_steps: 0
[36m(WorkerDict pid=2302369)[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention
[36m(WorkerDict pid=2302369)[0m Skipping monkey patch for Qwen2ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch
[36m(WorkerDict pid=2302369)[0m Applying LoRA to actor module
[36m(WorkerDict pid=2301407)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=2301407)[0m Actor use_fused_kernels=False
[33m(raylet)[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff07beb6bf6fd50e4ef4611b1001000000 Worker ID: f40d92df355a0947b9aa39d50ea0e9ed67bd81c18b61ab2085e27cdc Node ID: 41d9c491d33f325915d407ae48bfcd79129cb08c0b78fe88706357b3 Worker IP address: 128.32.162.167 Worker port: 39783 Worker PID: 2301407 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.
[33m(raylet)[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff68401c7e4272aafe53559c9801000000 Worker ID: d2b6310f8dfd4d04b3b0eb6ce5f45ca3cacc82c507feb15550a5d759 Node ID: 41d9c491d33f325915d407ae48bfcd79129cb08c0b78fe88706357b3 Worker IP address: 128.32.162.167 Worker port: 37409 Worker PID: 2302369 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.
2025-08-16 22:35:51,244	INFO worker.py:1918 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
[36m(TaskRunner pid=2301042)[0m 
Filtering prompts longer than 1024 tokens:   0%|          | 0/134 [00:00<?, ? examples/s]
[36m(TaskRunner pid=2301042)[0m 
Filtering prompts longer than 1024 tokens: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 134/134 [00:00<00:00, 559.61 examples/s]
Filtering prompts longer than 1024 tokens: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 134/134 [00:00<00:00, 554.58 examples/s]
[36m(TaskRunner pid=2301042)[0m 
Filtering prompts longer than 1024 tokens:   0%|          | 0/134 [00:00<?, ? examples/s]
[36m(TaskRunner pid=2301042)[0m 
Filtering prompts longer than 1024 tokens: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 134/134 [00:00<00:00, 634.85 examples/s]
Filtering prompts longer than 1024 tokens: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 134/134 [00:00<00:00, 628.88 examples/s]
[36m(TaskRunner pid=2301042)[0m /home/nickatomlin/georgiazhou/new_dialop/verl/verl/trainer/main_ppo.py:265: UserWarning: Disabled critic as algorithm.adv_estimator != gae. If it is not intended, please set critic.enable=True
[36m(TaskRunner pid=2301042)[0m   trainer = RayPPOTrainer(
[36m(TaskRunner pid=2301042)[0m /home/nickatomlin/georgiazhou/new_dialop/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(TaskRunner pid=2301042)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(TaskRunner pid=2301042)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2301042)[0m WARNING:2025-08-16 22:36:04,799:Waiting for register center actor oBokxi_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(WorkerDict pid=2302369)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen 2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=2302369)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=2302369)[0m 
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=2302369)[0m 
Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  4.78s/it]
[36m(WorkerDict pid=2301407)[0m Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2Model is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=2301407)[0m 
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(WorkerDict pid=2301407)[0m 
Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:13<00:04,  4.36s/it][32m [repeated 4x across cluster][0m
[36m(WorkerDict pid=2301407)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:17<00:00,  4.23s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:17<00:00,  4.30s/it]
[36m(WorkerDict pid=2302369)[0m /home/nickatomlin/georgiazhou/new_dialop/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(WorkerDict pid=2302369)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(WorkerDict pid=2302369)[0m 
Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:14<00:04,  4.67s/it]
[36m(WorkerDict pid=2302369)[0m 
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  4.54s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:18<00:00,  4.60s/it]
[36m(WorkerDict pid=2301407)[0m [2025-08-16 22:37:24] Scheduler hit an exception: Traceback (most recent call last):
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2534, in run_scheduler_process
[36m(WorkerDict pid=2301407)[0m     scheduler = Scheduler(
[36m(WorkerDict pid=2301407)[0m                 ^^^^^^^^^^
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 313, in __init__
[36m(WorkerDict pid=2301407)[0m     self.tp_worker = TpWorkerClass(
[36m(WorkerDict pid=2301407)[0m                      ^^^^^^^^^^^^^^
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/managers/tp_worker_overlap_thread.py", line 67, in __init__
[36m(WorkerDict pid=2301407)[0m     self.worker = TpModelWorker(
[36m(WorkerDict pid=2301407)[0m                   ^^^^^^^^^^^^^^
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 84, in __init__
[36m(WorkerDict pid=2301407)[0m     self.model_runner = ModelRunner(
[36m(WorkerDict pid=2301407)[0m                         ^^^^^^^^^^^^
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 242, in __init__
[36m(WorkerDict pid=2301407)[0m     self.initialize(min_per_gpu_memory)
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 285, in initialize
[36m(WorkerDict pid=2301407)[0m     self.load_model()
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 643, in load_model
[36m(WorkerDict pid=2301407)[0m     self.model = get_model(
[36m(WorkerDict pid=2301407)[0m                  ^^^^^^^^^^
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/model_loader/__init__.py", line 22, in get_model
[36m(WorkerDict pid=2301407)[0m     return loader.load_model(
[36m(WorkerDict pid=2301407)[0m            ^^^^^^^^^^^^^^^^^^
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/model_loader/loader.py", line 559, in load_model
[36m(WorkerDict pid=2301407)[0m     model = _initialize_model(
[36m(WorkerDict pid=2301407)[0m             ^^^^^^^^^^^^^^^^^^
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/model_loader/loader.py", line 174, in _initialize_model
[36m(WorkerDict pid=2301407)[0m     return model_class(
[36m(WorkerDict pid=2301407)[0m            ^^^^^^^^^^^^
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/models/qwen2.py", line 413, in __init__
[36m(WorkerDict pid=2301407)[0m     self.model = Qwen2Model(
[36m(WorkerDict pid=2301407)[0m                  ^^^^^^^^^^^
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/models/qwen2.py", line 266, in __init__
[36m(WorkerDict pid=2301407)[0m     self.embed_tokens = VocabParallelEmbedding(
[36m(WorkerDict pid=2301407)[0m                         ^^^^^^^^^^^^^^^^^^^^^^^
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/layers/vocab_parallel_embedding.py", line 293, in __init__
[36m(WorkerDict pid=2301407)[0m     self.quant_method.create_weights(
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/layers/quantization/unquant.py", line 59, in create_weights
[36m(WorkerDict pid=2301407)[0m     torch.empty(
[36m(WorkerDict pid=2301407)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[36m(WorkerDict pid=2301407)[0m     return func(*args, **kwargs)
[36m(WorkerDict pid=2301407)[0m            ^^^^^^^^^^^^^^^^^^^^^
[36m(WorkerDict pid=2301407)[0m RuntimeError: torch.cuda.MemPool doesn't currently support expandable_segments.
[36m(WorkerDict pid=2301407)[0m 
[36m(WorkerDict pid=2301407)[0m /home/nickatomlin/georgiazhou/new_dialop/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.
[36m(WorkerDict pid=2301407)[0m   warnings.warn("Torch profiler tool config is not fully supported now.", stacklevel=1)
[36m(WorkerDict pid=2302369)[0m 
Error executing job with overrides: ['algorithm.adv_estimator=grpo', 'algorithm.use_kl_in_reward=false', 'data.train_files=["/home/nickatomlin/georgiazhou/new_dialop/RL-matching/data/matching.parquet"]', 'data.val_files=["/home/nickatomlin/georgiazhou/new_dialop/RL-matching/data/matching.parquet"]', 'data.prompt_key=messages', 'data.train_batch_size=32', 'data.max_prompt_length=1024', 'data.max_response_length=256', 'data.filter_overlong_prompts=true', 'data.truncation=left', 'data.return_raw_chat=true', 'actor_rollout_ref.model.path=Qwen/Qwen2.5-7B-Instruct', 'actor_rollout_ref.model.enable_gradient_checkpointing=true', 'actor_rollout_ref.model.use_remove_padding=true', 'actor_rollout_ref.model.lora_rank=8', 'actor_rollout_ref.model.lora_alpha=16', 'actor_rollout_ref.model.target_modules=["q_proj","k_proj","v_proj","o_proj"]', 'actor_rollout_ref.actor.ppo_mini_batch_size=32', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1', 'actor_rollout_ref.actor.use_torch_compile=false', 'actor_rollout_ref.actor.fsdp_config.param_offload=true', 'actor_rollout_ref.actor.fsdp_config.optimizer_offload=true', 'actor_rollout_ref.rollout.name=sglang', 'actor_rollout_ref.rollout.multi_turn.enable=true', 'actor_rollout_ref.rollout.multi_turn.interaction_config_path=/home/nickatomlin/georgiazhou/new_dialop/RL-matching/configs/matching_interaction.yaml', 'actor_rollout_ref.rollout.prompt_length=1024', 'actor_rollout_ref.rollout.response_length=256', 'actor_rollout_ref.rollout.n=2', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.5', 'actor_rollout_ref.rollout.enable_chunked_prefill=true', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=1', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=1', 'critic.model.path=Qwen/Qwen2.5-7B-Instruct', 'critic.model.enable_gradient_checkpointing=true', 'critic.model.use_remove_padding=true', 'critic.model.lora_rank=8', 'critic.model.lora_alpha=16', 'critic.model.target_modules=["q_proj","k_proj","v_proj","o_proj"]', 'critic.ppo_micro_batch_size_per_gpu=1', 'reward_model.enable=false', 'trainer.project_name=verl_matching', 'trainer.experiment_name=grpo_7b_training_mem_opt', 'trainer.logger=["console"]', 'trainer.n_gpus_per_node=2', 'trainer.nnodes=1', 'trainer.save_freq=1', 'trainer.test_freq=1', 'trainer.total_epochs=3', 'trainer.critic_warmup=0']
Traceback (most recent call last):
  File "/home/nickatomlin/georgiazhou/new_dialop/verl/verl/trainer/main_ppo.py", line 40, in main
    run_ppo(config)
  File "/home/nickatomlin/georgiazhou/new_dialop/verl/verl/trainer/main_ppo.py", line 80, in run_ppo
    ray.get(runner.run.remote(config))
  File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/ray/_private/worker.py", line 2858, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/ray/_private/worker.py", line 958, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ActorDiedError): [36mray::TaskRunner.run()[39m (pid=2301042, ip=128.32.162.167, actor_id=e56530aeb227f11874469a6d01000000, repr=<main_ppo.TaskRunner object at 0x70b72a29b310>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nickatomlin/georgiazhou/new_dialop/verl/verl/trainer/main_ppo.py", line 280, in run
    trainer.init_workers()
  File "/home/nickatomlin/georgiazhou/new_dialop/verl/verl/trainer/ppo/ray_trainer.py", line 871, in init_workers
    self.actor_rollout_wg.init_model()
  File "/home/nickatomlin/georgiazhou/new_dialop/verl/verl/single_controller/ray/base.py", line 50, in __call__
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ray.exceptions.ActorDiedError: The actor died unexpectedly before finishing this task.
	class_name: create_colocated_worker_cls.<locals>.WorkerDict
	actor_id: 07beb6bf6fd50e4ef4611b1001000000
	pid: 2301407
	name: oBokxiWorkerDict_0:0
	namespace: a321dccd-180c-486b-afb7-62ee41a09af2
	ip: 128.32.162.167
The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(WorkerDict pid=2302369)[0m [2025-08-16 22:37:24] Scheduler hit an exception: Traceback (most recent call last):
[36m(WorkerDict pid=2302369)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2534, in run_scheduler_process
[36m(WorkerDict pid=2302369)[0m     scheduler = Scheduler(
[36m(WorkerDict pid=2302369)[0m                  ^^^^^^^^^^[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=2302369)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/layers/vocab_parallel_embedding.py", line 293, in __init__[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2302369)[0m     self.tp_worker = TpWorkerClass(
[36m(WorkerDict pid=2302369)[0m                   ^^^^^^^^^^^^^^[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=2302369)[0m     self.worker = TpModelWorker(
[36m(WorkerDict pid=2302369)[0m     self.model_runner = ModelRunner(
[36m(WorkerDict pid=2302369)[0m            ^^^^^^^^^^^^[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=2302369)[0m     self.initialize(min_per_gpu_memory)
[36m(WorkerDict pid=2302369)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 285, in initialize
[36m(WorkerDict pid=2302369)[0m     self.load_model()
[36m(WorkerDict pid=2302369)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/model_loader/loader.py", line 559, in load_model[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=2302369)[0m     self.model = get_model(
[36m(WorkerDict pid=2302369)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/model_loader/__init__.py", line 22, in get_model
[36m(WorkerDict pid=2302369)[0m     return loader.load_model(
[36m(WorkerDict pid=2302369)[0m             ^^^^^^^^^^^^^^^^^^[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=2302369)[0m     model = _initialize_model(
[36m(WorkerDict pid=2302369)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/model_loader/loader.py", line 174, in _initialize_model
[36m(WorkerDict pid=2302369)[0m     return model_class(
[36m(WorkerDict pid=2302369)[0m     self.model = Qwen2Model(
[36m(WorkerDict pid=2302369)[0m                  ^^^^^^^^^^^
[36m(WorkerDict pid=2302369)[0m     self.embed_tokens = VocabParallelEmbedding(
[36m(WorkerDict pid=2302369)[0m                         ^^^^^^^^^^^^^^^^^^^^^^^
[36m(WorkerDict pid=2302369)[0m     self.quant_method.create_weights(
[36m(WorkerDict pid=2302369)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/sglang/srt/layers/quantization/unquant.py", line 59, in create_weights
[36m(WorkerDict pid=2302369)[0m     torch.empty(
[36m(WorkerDict pid=2302369)[0m   File "/home/nickatomlin/sources/conda/envs/verl311/lib/python3.11/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[36m(WorkerDict pid=2302369)[0m     return func(*args, **kwargs)
[36m(WorkerDict pid=2302369)[0m            ^^^^^^^^^^^^^^^^^^^^^
[36m(WorkerDict pid=2302369)[0m RuntimeError: torch.cuda.MemPool doesn't currently support expandable_segments.

ERROR conda.cli.main_run:execute(49): `conda run python -m verl.trainer.main_ppo algorithm.adv_estimator=grpo algorithm.use_kl_in_reward=false data.train_files=["/home/nickatomlin/georgiazhou/new_dialop/RL-matching/data/matching.parquet"] data.val_files=["/home/nickatomlin/georgiazhou/new_dialop/RL-matching/data/matching.parquet"] data.prompt_key=messages data.train_batch_size=32 data.max_prompt_length=1024 data.max_response_length=256 data.filter_overlong_prompts=true data.truncation=left data.return_raw_chat=true actor_rollout_ref.model.path=Qwen/Qwen2.5-7B-Instruct actor_rollout_ref.model.enable_gradient_checkpointing=true actor_rollout_ref.model.use_remove_padding=true actor_rollout_ref.model.lora_rank=8 actor_rollout_ref.model.lora_alpha=16 actor_rollout_ref.model.target_modules=["q_proj","k_proj","v_proj","o_proj"] actor_rollout_ref.actor.ppo_mini_batch_size=32 actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 actor_rollout_ref.actor.use_torch_compile=false actor_rollout_ref.actor.fsdp_config.param_offload=true actor_rollout_ref.actor.fsdp_config.optimizer_offload=true actor_rollout_ref.rollout.name=sglang actor_rollout_ref.rollout.multi_turn.enable=true actor_rollout_ref.rollout.multi_turn.interaction_config_path=/home/nickatomlin/georgiazhou/new_dialop/RL-matching/configs/matching_interaction.yaml actor_rollout_ref.rollout.prompt_length=1024 actor_rollout_ref.rollout.response_length=256 actor_rollout_ref.rollout.n=2 actor_rollout_ref.rollout.tensor_model_parallel_size=1 actor_rollout_ref.rollout.gpu_memory_utilization=0.5 actor_rollout_ref.rollout.enable_chunked_prefill=true actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=1 actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=1 critic.model.path=Qwen/Qwen2.5-7B-Instruct critic.model.enable_gradient_checkpointing=true critic.model.use_remove_padding=true critic.model.lora_rank=8 critic.model.lora_alpha=16 critic.model.target_modules=["q_proj","k_proj","v_proj","o_proj"] critic.ppo_micro_batch_size_per_gpu=1 reward_model.enable=false trainer.project_name=verl_matching trainer.experiment_name=grpo_7b_training_mem_opt trainer.logger=["console"] trainer.n_gpus_per_node=2 trainer.nnodes=1 trainer.save_freq=1 trainer.test_freq=1 trainer.total_epochs=3 trainer.critic_warmup=0` failed. (See above for error)

